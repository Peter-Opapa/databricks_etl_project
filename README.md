# ğŸ—ï¸ End-to-End Data Pipeline: Fivetran â†’ Databricks Lakehouse (DLT, CDC, SCD)

This project demonstrates a complete, production-ready **ETL pipeline** that ingests data from **Google Drive via Fivetran**, processes it through the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) using **PySpark** and **Delta Live Tables**, and applies **CDC** and **SCD** logic to maintain up-to-date business records. The pipeline follows the **Star Schema** modeling technique, utilizes **parameterized notebooks** for dynamic ingestion/transformation, and is orchestrated using **LakeFlow Declrative Pipeline**.

---

## ğŸ§­ Architecture Overview

![Architecture Diagram](images/Architecture.png)

---

## ğŸ§° Tools & Technologies

| Tool / Tech                 | Role                                                                 |
|-----------------------------|----------------------------------------------------------------------|
| **Fivetran**                | Automated ELT from Google Drive to Databricks                       |
| **Google Drive**            | Source of raw Excel/CSV files                                       |
| **Databricks Auto Loader**  | Ingest files into Bronze with schema inference                      |
| **PySpark / Spark SQL**     | Data cleansing, enrichment, and transformation in Silver layer      |
| **Delta Live Tables (DLT)** | Declarative pipeline with CDC + SCD support in the Gold layer       |
| **Delta Lake**              | ACID-compliant, scalable lakehouse storage                          |
| **LakeFlow**                | Workflow orchestration and visual pipeline management               |
| **Star Schema**             | Dimensional data modeling for analytics                             |
| **Medallion Architecture**  | Layered data design (Bronze â†’ Silver â†’ Gold)                        |
| **Parameterized Notebooks** | Dynamic and reusable notebooks for data loading & processing        |

---

## ğŸ”„ Data Pipeline Stages

### 1ï¸âƒ£ Bronze Layer â€“ Raw Ingestion

- Ingest data from **Google Drive** using **Fivetran** connectors.
- Store raw files in **Delta tables** using **Auto Loader**.
- Notebooks are **parameterized** to dynamically load different source tables.

### 2ï¸âƒ£ Silver Layer â€“ Cleansed Data

- Apply **PySpark** and **SQL** logic to clean, join, filter, and structure the data.
- Star schema design with fact and dimension tables.
- Reuse **parameterized notebooks** to transform data from multiple sources.

### 3ï¸âƒ£ Gold Layer â€“ Business-ready Analytics

- Apply **CDC/SCD logic** via **Delta Live Tables (DLT)**.
- Implement slowly changing dimensions (SCD Type 1 and 2).
- Use LakeFlow for job orchestration and monitoring.

---

## ğŸŒŸ Data Modeling Approach

This pipeline uses the **Star Schema** for organizing transformed data into:
- **Fact Tables**: e.g., sales, transactions, etc.
- **Dimension Tables**: e.g., customers, products, time, region, etc.

Benefits:
- Simplifies BI queries
- Supports OLAP-style analysis
- Works well with tools like Power BI or Tableau

---

## ğŸ—‚ï¸ Medallion Architecture Layers

| Layer      | Format      | Description                                        |
|------------|-------------|----------------------------------------------------|
| **Bronze** | Raw Delta   | Unprocessed data directly from Fivetran            |
| **Silver** | Clean Delta | Transformed and joined data (pySpark&SQL)          |
| **Gold**   | Curated Delta| CDC/SCD-applied business-ready analytics layer     |

---
## ğŸ§ª Visuals

### ğŸ“Œ Pipeline Job Diagrams
![Pipeline Diagram](images/Pipeline_end_to_end.png)
![Pipeline Diagram](images/end_to_end_pipeline.png)
![Pipeline Diagram](images/overview.png)

### ğŸ“Œ LakeFlow Declarative Pipeline
![Pipeline Diagram](images/Lakeflow_Declarative_Pipeline.png)
![Pipeline Diagram](images/lakeflow_job_execution.png)

---
## ğŸ“‚ Project Structure
ğŸ“ databricks-lakehouse-pipeline/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Gold_Customers.ipynb
â”‚   â”œâ”€â”€ Gold_Orders.ipynb
â”‚   â”œâ”€â”€ Gold_Products.ipynb
|   â”œâ”€â”€ Silver_Customers.ipynb
|   â”œâ”€â”€ Silver_Orders.ipynb
|   â”œâ”€â”€ Silver_Products.ipynb
|   â”œâ”€â”€ Silver_Region.ipynb
|   â”œâ”€â”€ bronze_auto_loader.ipynb
|   â””â”€â”€ Parameters.ipynb
â”‚       
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ lakeflow_declarative_pipeline.png
â”‚   â”œâ”€â”€ pipeline_end_to_end.png
|   â”œâ”€â”€ end_to_end_pipeline.png
|   â”œâ”€â”€ lakeflow_job_execution.png
|   â””â”€â”€ overview.png
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


